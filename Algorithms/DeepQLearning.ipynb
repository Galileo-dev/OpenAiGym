{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Vdzp0ZRUDgAp"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     27\u001b[0m observation \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 28\u001b[0m discrete_state \u001b[38;5;241m=\u001b[39m \u001b[43mget_discrete_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminated:\n",
            "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mget_discrete_state\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_discrete_state\u001b[39m(state):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(((\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlow\u001b[49m) \u001b[38;5;241m/\u001b[39m discrete_os_win_size)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
            "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "env = gym.make(\"MountainCar-v0\")\n",
        "observation, info = env.reset()\n",
        "\n",
        "LEARING_RATE = 0.1\n",
        "DISCOUNT = 0.95\n",
        "EPISODES = 25000\n",
        "\n",
        "SHOW_EVERY = 2000\n",
        "\n",
        "DISCRETE_OS_SIZE = [20] * len(env.observation_space.high)\n",
        "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / DISCRETE_OS_SIZE\n",
        "\n",
        "q_table  = np.random.uniform(low=-2, high=0, size=(DISCRETE_OS_SIZE + [env.action_space.n])) # initialize the q table with random values\n",
        "\n",
        "def get_discrete_state(state):\n",
        "    return tuple(((state - env.observation_space.low) / discrete_os_win_size).astype(int))\n",
        "\n",
        "\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    if episode % SHOW_EVERY == 0:\n",
        "        print(episode)\n",
        "        render = True\n",
        "    else:\n",
        "        render = False\n",
        "    \n",
        "    observation, info = env.reset()\n",
        "    discrete_state = get_discrete_state(observation)\n",
        "    terminated = False\n",
        "    \n",
        "    while not terminated:\n",
        "        action = np.argmax(q_table[discrete_state])\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        print(reward, observation)\n",
        "\n",
        "        if render:\n",
        "            env.render()\n",
        "\n",
        "        new_discrete_state = get_discrete_state(observation)\n",
        "\n",
        "        if not terminated:\n",
        "\n",
        "            max_future_q = np.max(q_table[new_discrete_state])\n",
        "            current_q = q_table[discrete_state + (action,)]\n",
        "\n",
        "            new_q = (1-LEARING_RATE) * current_q + LEARING_RATE * (reward + DISCOUNT * max_future_q)\n",
        "            q_table[discrete_state + (action,)] = new_q\n",
        "\n",
        "        elif observation[0] >= env.goal_position:\n",
        "            print(f\"We made it on episode {_}\")\n",
        "            q_table[discrete_state + (action,)] = 0\n",
        "        \n",
        "        discrete_state = new_discrete_state\n",
        "\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMAcuMDMcsHCDLN2hZlxcD6",
      "include_colab_link": true,
      "name": "DeepQLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
